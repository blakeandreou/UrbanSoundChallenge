{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6bb922-8547-42c9-a47f-a46aec5075ea",
   "metadata": {},
   "source": [
    "# Urban Sound Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302eebbc-9c03-42bf-ae5c-0e7436d6c090",
   "metadata": {},
   "source": [
    "_Project designed to utilize signal processing and machine learning techniques to classifying a group of 10 different categories of urban sounds._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262dd38f-fc7d-4d35-9eb7-155bf65a2c1e",
   "metadata": {},
   "source": [
    "_December 2023, by Blake Andreou_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9fe07-954c-4da3-997f-876272a43b99",
   "metadata": {},
   "source": [
    "#### Imports and Initial Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a4497a-57f5-4893-a933-a29d59d30d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundata\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c175a-8478-467f-a3c3-b10842237d86",
   "metadata": {},
   "source": [
    "_The file below can be utilized if one would like to re-derive the fetaures from the raw data. Raw data can be downloaded from the soundata Python package, and path will need to replace 'data home' path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c9db32-2071-4356-b41b-f0a2f7422f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 331.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8732/8732 [01:21<00:00, 107.65it/s]\n",
      "INFO: Success: the dataset is complete and all files are valid.\n",
      "INFO: --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'metadata': {}, 'clips': {}}, {'metadata': {}, 'clips': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grabbing sound dataset\n",
    "dataset = soundata.initialize('urbansound8k',data_home='C://Users/Blake/Documents/College_Stuff/JOBS/Projects/UrbanSoundChallenge/sound_datasets/urbansound8k')\n",
    "#downloading if data not already downloaded\n",
    "#dataset.download()\n",
    "#validation that dataset was downloaded correctly\n",
    "dataset.validate() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a528357-ce66-4500-8ea4-1f71b5a8bb85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Potentially usable information for featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2fbdae-1d12-4d94-981f-ee4df3a38bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic clip data\n",
    "sample_clip = dataset.choice_clip()\n",
    "print(sample_clip.audio) #access audio\n",
    "print(sample_clip.salience)\n",
    "print(sample_clip.class_id) #class label (0-9)\n",
    "print(sample_clip.class_label) #class label (string)\n",
    "print(sample_clip.fold) #generate which fold its in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef30118-b894-459d-9d29-d8bed8c85c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#playing a given sound\n",
    "from IPython.display import Audio\n",
    "sample_audio = sample_clip.audio\n",
    "audio_data = sample_audio[0]\n",
    "audio_sample_rate = sample_audio[1]\n",
    "Audio(data = audio_data, rate = audio_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5cdda-2e84-4622-b36d-47e9ce76e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating waveform of given sound\n",
    "def printWave(clip,class_label=''):\n",
    "    #imports\n",
    "    from librosa import display\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title(class_label)\n",
    "    librosa.display.waveshow(y = clip[0], sr = clip[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6630c4-387b-4b95-af1f-2e067282277a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Visualizing Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42177c52-352e-42c0-9a95-679eefa672c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['air conditioner','car horn','children playing','dog bark','drilling',\n",
    "                'engine idling','gun shot','jackhammer','siren','street music']\n",
    "class_accessed = [False] * 10\n",
    "#get all clips and ids\n",
    "all_clips = dataset.load_clips()\n",
    "all_ids = dataset.clip_ids\n",
    "#cycle through all clip ids as necessary\n",
    "for id in all_ids:\n",
    "    #get clip\n",
    "    clip = all_clips[id]\n",
    "    #if condition isn't printed yet\n",
    "    if(class_accessed[clip.class_id] == False):\n",
    "        printWave(clip.audio,class_label=class_labels[clip.class_id])\n",
    "        class_accessed[clip.class_id] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41b08f-46c0-40ab-9360-1474b9269ce1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b07316-e25f-4e47-8bc3-499d77317398",
   "metadata": {},
   "source": [
    "_Skip this section if one is just interesting in modeling portion, unpickling included files will provide the output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c795a63-30d5-4672-b37c-4387576ac2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get relevant features (mfccs)\n",
    "features = []\n",
    "folds = []\n",
    "labels = []\n",
    "#get each clip via id\n",
    "for id in all_ids:\n",
    "    clip = all_clips[id]\n",
    "    #generate feature set\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=clip.audio[0], sr=clip.audio[1]).T,axis=0)\n",
    "    features.append(mfccs)\n",
    "    folds.append(clip.fold)\n",
    "    labels.append(clip.class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97082526-9526-4041-8b4f-22562549ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get additional features (mfccs)\n",
    "moreFeatures = []\n",
    "#get each clip via id\n",
    "for id in all_ids:\n",
    "    clip = all_clips[id]\n",
    "    #generate feature set\n",
    "    data = np.mean(librosa.feature.mfcc(y=clip.audio[0], sr=clip.audio[1]).T,axis=0) #mfcc\n",
    "    data = np.append(data,clip.freesound_end_time-clip.freesound_start_time) #length of clip (relevant for shorter ones like horn/gunshot)\n",
    "    data = np.append(data,sum(librosa.zero_crossings(clip.audio[0]))) #zero crossings (maybe relevant for higher freq. identifiers?)\n",
    "    moreFeatures.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd462e7-0e10-4d6b-aea3-7352dee11115",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pickling/Unpickling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948c61f-f0a1-4c16-b60c-7dfd1716a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling of relevant data to avoid taxing cell above\n",
    "with open('mfcss_only_features.pkl', 'wb') as file:\n",
    "    pickle.dump(features, file)\n",
    "\n",
    "with open('labels.pkl', 'wb') as file:\n",
    "    pickle.dump(labels, file)\n",
    "\n",
    "with open('folds.pkl', 'wb') as file:\n",
    "    pickle.dump(folds, file)\n",
    "\n",
    "with open('all_features.pkl', 'wb') as file:\n",
    "    pickle.dump(moreFeatures, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf98f498-d089-44b0-83be-9cabf95a0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpickling as needed\n",
    "with open('mfcss_only_features.pkl', 'rb') as file:\n",
    "    features = pickle.load(file)\n",
    "    \n",
    "with open('labels.pkl', 'rb') as file:\n",
    "    labels = pickle.load(file)\n",
    "    \n",
    "with open('folds.pkl', 'rb') as file:\n",
    "    folds = pickle.load(file)\n",
    "    \n",
    "with open('all_features.pkl', 'rb') as file:\n",
    "    moreFeatures = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338cfb1-9628-4c97-85ed-fdf5d69ee684",
   "metadata": {},
   "source": [
    "#### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5416429-98e6-472f-9fc3-aa33adb6ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFModel(input_size):\n",
    "    #standard model,nothing special\n",
    "    import numpy as np\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.regularizers import L2\n",
    "    from keras.utils import np_utils\n",
    "    from sklearn import metrics \n",
    "\n",
    "    num_labels = len(labels)\n",
    "    filter_size = 2\n",
    "\n",
    "    # build model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(input_size,)))\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512,activation='relu',kernel_regularizer=L2(l2=0.05)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_labels,activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2046ab1-e65b-497d-9285-c2f2944bb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(input_size):\n",
    "    #adding LSTM\n",
    "    import numpy as np\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.regularizers import L2\n",
    "    from keras.utils import np_utils\n",
    "    from sklearn import metrics \n",
    "\n",
    "    num_labels = len(labels)\n",
    "    filter_size = 2\n",
    "\n",
    "    # build model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(256, input_shape=(input_size,1)))    \n",
    "    model.add(Dense(512,activation='relu',kernel_regularizer=L2(l2=0.05)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_labels,activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50081bfb-6475-470d-aeb5-9d7ffc72e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticModel(input_size):\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Input, Dense, Dropout, Activation\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.utils import np_utils\n",
    "    from sklearn import metrics \n",
    "\n",
    "    num_labels = len(labels)\n",
    "    filter_size = 2\n",
    "\n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_size,)))\n",
    "    model.add(Dense(num_labels,activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227ec44c-0502-41d4-95db-14d931fd9ed6",
   "metadata": {},
   "source": [
    "#### Model Run and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fae6be-83fe-43e0-9bed-f33c7df06739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(modelFunc,trainFeatures,trainLabels,testFeatures,testLabels,epochs,batch,input_size):\n",
    "    model = modelFunc(input_size)\n",
    "    model.fit([x.tolist() for x in trainFeatures], trainLabels, batch_size=batch, epochs=epochs,verbose=0)\n",
    "    model.evaluate([x.tolist() for x in testFeatures], testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0141ad5-d400-4692-91b6-9dd4664ae383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValRun(modelFunc,features,epochs=5,batchSize=32):\n",
    "    #cross validation up to fold 9\n",
    "    input_size = len(features[0])\n",
    "    prevBreaker = 0\n",
    "    for fold in range(1,10):\n",
    "        print('\\nFOLD ' + str(fold) + ' RUN:\\n')\n",
    "        #data split\n",
    "        currBreaker = folds.index(fold+1)\n",
    "        testFeatures = features[prevBreaker:currBreaker]\n",
    "        trainFeatures = features[:prevBreaker] + features[currBreaker:]\n",
    "        testLabels = labels[prevBreaker:currBreaker]\n",
    "        trainLabels = labels[:prevBreaker] + labels[currBreaker:]\n",
    "        #run model\n",
    "        runModel(modelFunc,trainFeatures,trainLabels,testFeatures,testLabels,epochs,batchSize,input_size)\n",
    "        prevBreaker = currBreaker\n",
    "    #fold 10 separate\n",
    "    print('\\nFOLD 10 RUN:\\n')\n",
    "    #data split\n",
    "    testFeatures = features[currBreaker:]\n",
    "    trainFeatures = features[:currBreaker]\n",
    "    testLabels = labels[currBreaker:]\n",
    "    trainLabels = labels[:currBreaker]\n",
    "    #run model\n",
    "    runModel(modelFunc,trainFeatures,trainLabels,testFeatures,testLabels,epochs,batchSize,input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f8df63-4b38-4938-9cea-b3dcfb12d8ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------logisticModel with all features-----------\n",
      "\n",
      "FOLD 1 RUN:\n",
      "\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 4.1407 - accuracy: 0.4399\n",
      "\n",
      "FOLD 2 RUN:\n",
      "\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 4.2087 - accuracy: 0.2928\n",
      "\n",
      "FOLD 3 RUN:\n",
      "\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.9731 - accuracy: 0.4173\n",
      "\n",
      "FOLD 4 RUN:\n",
      "\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 2.9688 - accuracy: 0.4111\n",
      "\n",
      "FOLD 5 RUN:\n",
      "\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 4.4476 - accuracy: 0.3291\n",
      "\n",
      "FOLD 6 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.0463 - accuracy: 0.3098\n",
      "\n",
      "FOLD 7 RUN:\n",
      "\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 2.1132 - accuracy: 0.4224\n",
      "\n",
      "FOLD 8 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.4226 - accuracy: 0.4194\n",
      "\n",
      "FOLD 9 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.9960 - accuracy: 0.3909\n",
      "\n",
      "FOLD 10 RUN:\n",
      "\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3.2168 - accuracy: 0.3226\n",
      "---------FFModel with all features-----------\n",
      "\n",
      "FOLD 1 RUN:\n",
      "\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1748 - accuracy: 0.2268\n",
      "\n",
      "FOLD 2 RUN:\n",
      "\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.0850 - accuracy: 0.1768\n",
      "\n",
      "FOLD 3 RUN:\n",
      "\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 5.8953 - accuracy: 0.2054\n",
      "\n",
      "FOLD 4 RUN:\n",
      "\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 6.3030 - accuracy: 0.1677\n",
      "\n",
      "FOLD 5 RUN:\n",
      "\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 5.8990 - accuracy: 0.2062\n",
      "\n",
      "FOLD 6 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 5.9166 - accuracy: 0.1968\n",
      "\n",
      "FOLD 7 RUN:\n",
      "\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 5.8432 - accuracy: 0.1420\n",
      "\n",
      "FOLD 8 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 5.4313 - accuracy: 0.2866\n",
      "\n",
      "FOLD 9 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 5.2604 - accuracy: 0.1998\n",
      "\n",
      "FOLD 10 RUN:\n",
      "\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 5.8788 - accuracy: 0.1732\n",
      "---------LSTM with all features-----------\n",
      "\n",
      "FOLD 1 RUN:\n",
      "\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 1.9916 - accuracy: 0.3070\n",
      "\n",
      "FOLD 2 RUN:\n",
      "\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.3064 - accuracy: 0.1126\n",
      "\n",
      "FOLD 3 RUN:\n",
      "\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2.3050 - accuracy: 0.1276\n",
      "\n",
      "FOLD 4 RUN:\n",
      "\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 2.3040 - accuracy: 0.1010\n",
      "\n",
      "FOLD 5 RUN:\n",
      "\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 2.3283 - accuracy: 0.0759\n",
      "\n",
      "FOLD 6 RUN:\n",
      "\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 2.3038 - accuracy: 0.1215\n",
      "\n",
      "FOLD 7 RUN:\n",
      "\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 2.2993 - accuracy: 0.1193\n",
      "\n",
      "FOLD 8 RUN:\n",
      "\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.8434 - accuracy: 0.3759\n",
      "\n",
      "FOLD 9 RUN:\n",
      "\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 2.2792 - accuracy: 0.1091\n",
      "\n",
      "FOLD 10 RUN:\n",
      "\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.2712 - accuracy: 0.1195\n"
     ]
    }
   ],
   "source": [
    "#Running and testing each model with all features\n",
    "for model in [logisticModel,FFModel,LSTM]:\n",
    "    print(\"---------\" + model.__name__ + \" with all features-----------\")\n",
    "    crossValRun(model,moreFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6219df9c-7b30-4f1c-ad26-2a96131c6757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------logisticModel with only MFCSS features-----------\n",
      "\n",
      "FOLD 1 RUN:\n",
      "\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.2397 - accuracy: 0.4204\n",
      "\n",
      "FOLD 2 RUN:\n",
      "\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.7344 - accuracy: 0.4155\n",
      "\n",
      "FOLD 3 RUN:\n",
      "\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.5396 - accuracy: 0.4886\n",
      "\n",
      "FOLD 4 RUN:\n",
      "\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.6894 - accuracy: 0.4929\n",
      "\n",
      "FOLD 5 RUN:\n",
      "\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4721 - accuracy: 0.4316\n",
      "\n",
      "FOLD 6 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.7333 - accuracy: 0.4204\n",
      "\n",
      "FOLD 7 RUN:\n",
      "\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 1.5665 - accuracy: 0.4499\n",
      "\n",
      "FOLD 8 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.6436 - accuracy: 0.5012\n",
      "\n",
      "FOLD 9 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.6493 - accuracy: 0.4559\n",
      "\n",
      "FOLD 10 RUN:\n",
      "\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 1.8792 - accuracy: 0.4600\n",
      "---------FFModel with only MFCSS features-----------\n",
      "\n",
      "FOLD 1 RUN:\n",
      "\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 2.3719 - accuracy: 0.4479\n",
      "\n",
      "FOLD 2 RUN:\n",
      "\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 2.1732 - accuracy: 0.4167\n",
      "\n",
      "FOLD 3 RUN:\n",
      "\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.9296 - accuracy: 0.4497\n",
      "\n",
      "FOLD 4 RUN:\n",
      "\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.7698 - accuracy: 0.5051\n",
      "\n",
      "FOLD 5 RUN:\n",
      "\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.5905 - accuracy: 0.5363\n",
      "\n",
      "FOLD 6 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.7976 - accuracy: 0.5346\n",
      "\n",
      "FOLD 7 RUN:\n",
      "\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.6863 - accuracy: 0.4869\n",
      "\n",
      "FOLD 8 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.7131 - accuracy: 0.5955\n",
      "\n",
      "FOLD 9 RUN:\n",
      "\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.7837 - accuracy: 0.5429\n",
      "\n",
      "FOLD 10 RUN:\n",
      "\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 1.8145 - accuracy: 0.5400\n",
      "---------LSTM with only MFCSS features-----------\n",
      "\n",
      "FOLD 1 RUN:\n",
      "\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 1.9720 - accuracy: 0.3322\n",
      "\n",
      "FOLD 2 RUN:\n",
      "\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 1.9955 - accuracy: 0.3029\n",
      "\n",
      "FOLD 3 RUN:\n",
      "\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2.1060 - accuracy: 0.2486\n",
      "\n",
      "FOLD 4 RUN:\n",
      "\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.0512 - accuracy: 0.3263\n",
      "\n",
      "FOLD 5 RUN:\n",
      "\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 1.9205 - accuracy: 0.3579\n",
      "\n",
      "FOLD 6 RUN:\n",
      "\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.9732 - accuracy: 0.3548\n",
      "\n",
      "FOLD 7 RUN:\n",
      "\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.9742 - accuracy: 0.3652\n",
      "\n",
      "FOLD 8 RUN:\n",
      "\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.7645 - accuracy: 0.3524\n",
      "\n",
      "FOLD 9 RUN:\n",
      "\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.8792 - accuracy: 0.3725\n",
      "\n",
      "FOLD 10 RUN:\n",
      "\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.9709 - accuracy: 0.3405\n"
     ]
    }
   ],
   "source": [
    "#Running and testing features with MCFSS features\n",
    "for model in [logisticModel,FFModel,LSTM]:\n",
    "    print(\"---------\" + model.__name__ + \" with only MFCSS features-----------\")\n",
    "    crossValRun(model,features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AUDIO",
   "language": "python",
   "name": "audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
